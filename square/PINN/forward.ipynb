{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b792e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (for Google Colab)\n",
    "!pip install pyDOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle\n",
    "import jax, flax, optax\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "from functools import partial\n",
    "from pyDOE import lhs\n",
    "from typing import Sequence, Callable\n",
    "import json\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359462d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must set CUDA_VISIBLE_DEVICES before importing JAX or any other library that initializes GPUs.\n",
    "# Otherwise, the environment variable change might be ignored.\n",
    "# \"0, 1\": first two GPUs / \"\": no GPU (CPU instead)\n",
    "\n",
    "# Run on the first GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from jax.extend.backend import get_backend\n",
    "print(get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4395d8",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_list = [[20, 2], [60, 2], [20, 20, 2], [60, 60, 2],\n",
    "                     [20, 20, 20, 2], [60, 60, 60, 2],\n",
    "                     [20, 20, 20, 20, 2], [60, 60, 60, 60, 2],\n",
    "                     [20, 20, 20, 20, 20, 2], [60, 60, 60, 60, 60, 2],\n",
    "                     [120, 120, 120, 120, 120, 2]] # NN architecture list\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 20000 # number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd6f92",
   "metadata": {},
   "source": [
    "# NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NN architecture\n",
    "class PDESolution(flax.linen.Module): # inherit from Module class\n",
    "    # One behavior of \"flax.linen.Module\" is to assign the provided argument to the \"self.features\"\n",
    "    features: Sequence[int] # dataclass (e.g. [10, 20, 2])\n",
    "\n",
    "    @flax.linen.compact # a decorator to define the model in more concise and readable way\n",
    "    def __call__(self, x): # __call__: makes an object callable, which enables you to use instances of the class like functions\n",
    "        for feature in self.features[:-1]:\n",
    "            x = flax.linen.tanh(flax.linen.Dense(feature)(x))\n",
    "        # Final Dense layer\n",
    "        x = flax.linen.Dense(self.features[-1])(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfe7928",
   "metadata": {},
   "source": [
    "# Stress Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad2f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4dcc721",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b144380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE residual\n",
    "@partial(jax.vmap, in_axes = (None, 0, 0), out_axes = 0)\n",
    "@partial(jax.jit, static_argnums = (0,)) # decorator closest to the function is applied first\n",
    "def residual1(u, x, y):\n",
    "    def stress(x, y): # tensor\n",
    "        E = 2.35e3\n",
    "        nu = 0.33\n",
    "        mu = E / (2. * (1 + nu))\n",
    "        lmbda = E * nu / ((1 + nu) * (1 - 2*nu))\n",
    "        u_grad = jax.jacobian(u)(x, y)\n",
    "        epsilon = 0.5 * (u_grad + u_grad.T) # (2, 2)\n",
    "        # Stress-Strain relationship\n",
    "        sigma = lmbda * np.trace(epsilon) * np.eye(2) + 2 * mu * epsilon \n",
    "        return sigma\n",
    "\n",
    "    jac_wrt_x = jax.jacobian(stress, argnums=0)(x, y)\n",
    "    jac_wrt_y = jax.jacobian(stress, argnums=1)(x, y)\n",
    "    dsigma11_dx = jac_wrt_x[0, 0]\n",
    "    dsigma12_dy = jac_wrt_y[0, 1]\n",
    "    lhs = dsigma11_dx + dsigma12_dy\n",
    "    rhs = 0.\n",
    "    return lhs - rhs\n",
    "\n",
    "@partial(jax.vmap, in_axes = (None, 0, 0), out_axes = 0)\n",
    "@partial(jax.jit, static_argnums = (0,))\n",
    "def residual2(u, x, y):\n",
    "    def stress(x, y): # tensor\n",
    "        E = 2.35e3\n",
    "        nu = 0.33\n",
    "        mu = E / (2. * (1 + nu))\n",
    "        lmbda = E * nu / ((1 + nu) * (1 - 2*nu))\n",
    "        u_grad = jax.jacobian(u)(x, y)\n",
    "        epsilon = 0.5 * (u_grad + u_grad.T) # (2, 2)\n",
    "        # Stress-Strain relationship\n",
    "        sigma = lmbda * np.trace(epsilon) * np.eye(2) + 2 * mu * epsilon \n",
    "        return sigma\n",
    "\n",
    "    jac_wrt_x = jax.jacobian(stress, argnums=0)(x, y)\n",
    "    jac_wrt_y = jax.jacobian(stress, argnums=1)(x, y)\n",
    "    dsigma21_dx = jac_wrt_x[1, 0]\n",
    "    dsigma22_dy = jac_wrt_y[1, 1]\n",
    "    lhs = dsigma21_dx + dsigma22_dy\n",
    "    rhs = 0.\n",
    "    return lhs - rhs\n",
    "\n",
    "# Loss functionals\n",
    "@jax.jit\n",
    "def pde_residual1(params, points):\n",
    "    return np.mean(residual1(lambda x, y: model.apply(params, np.stack((x, y))), points[:, 0], points[:, 1]) ** 2) # Mean Squared Error\n",
    "\n",
    "@jax.jit\n",
    "def pde_residual2(params, points):\n",
    "    return np.mean(residual2(lambda x, y: model.apply(params, np.stack((x, y))), points[:, 0], points[:, 1]) ** 2) # Mean Squared Error\n",
    "\n",
    "@jax.jit\n",
    "def dirichlet_residual1(params, points): # Γ_u = -1 at x = 0\n",
    "    return np.mean((model.apply(params, np.stack((np.zeros_like(points[:,1]), points[:,1]), axis=1))[:, 0] + 1.) ** 2)\n",
    "\n",
    "@jax.jit\n",
    "def dirichlet_residual2(params, points): # Γ_u = 1 at x = 40\n",
    "    return np.mean((model.apply(params, np.stack((40 * np.ones_like(points[:,0]), points[:,1]), axis=1))[:, 0] - 1.) ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20522bac",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Step\n",
    "@partial(jax.jit, static_argnums = (1, 4))\n",
    "def training_step(params, opt, opt_state, key, d_neumann: Callable = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        params: network + geometric parameters\n",
    "        opt: optimizer\n",
    "        opt_state: optimizer state\n",
    "        key: random key for sampling\n",
    "    \"\"\"\n",
    "    # Generate random samples (\"jax.grad\" cannot receive the function with randomness)\n",
    "    boundary_samples = lhs(2, 250)\n",
    "    angle_samples1 = lhs(1, 150)\n",
    "    angle_samples2 = lhs(1, 2000)\n",
    "    radius_samples = lhs(1, 2000)\n",
    "    \n",
    "    # Total loss functional\n",
    "    def loss_total(params, boundary_samples, angle_samples1, angle_samples2, radius_samples):\n",
    "        net_params = params['network']\n",
    "        geo_params = params['geometry']\n",
    "        x_cen, y_cen, a, b, gamma = geo_params # unpack geometric parameters\n",
    "\n",
    "        # Define the domain & external boundary points\n",
    "        lb = np.array([0., 0.]) # lower bound\n",
    "        ub = np.array([40., 40.]) # upper bound\n",
    "        boundary_points = lb + (ub - lb) * boundary_samples\n",
    "        boundary_points1 = np.column_stack((np.zeros_like(boundary_points[:, 0]), boundary_points[:, 1])) # latin hypercube sampling 150 points at x = 0\n",
    "        boundary_points2 = np.column_stack((boundary_points[:, 0], 40 * np.ones_like(boundary_points[:, 1])))\n",
    "\n",
    "        # Define the boundary points of the void\n",
    "        def ellipse(x_cen, y_cen, a, b, gamma, rotated_ang):\n",
    "            x = a * np.cos(rotated_ang) * np.cos(gamma) - b * np.sin(rotated_ang) * np.sin(gamma) + x_cen\n",
    "            y = a * np.cos(rotated_ang) * np.sin(gamma) + b * np.sin(rotated_ang) * np.cos(gamma) + y_cen\n",
    "            return np.array([x, y]).T\n",
    "        random_angle1 = 2 * np.pi * angle_samples1\n",
    "        void_boundary_points = ellipse(x_cen, y_cen, a, b, gamma, random_angle1)\n",
    "\n",
    "        # Define the domain points\n",
    "        random_angle2 = 2 * np.pi * angle_samples2\n",
    "        random_radius = np.sqrt(radius_samples)\n",
    "        domain_points = ellipse(x_cen, y_cen, a * random_radius, b * random_radius, gamma, random_angle2)\n",
    "        \n",
    "        # Define the loss function\n",
    "        loss_pde1 = pde_residual1({'params': net_params}, domain_points) # parameters to be used in \"model.apply\" should be in the dict with 'params' key.\n",
    "        loss_pde2 = pde_residual2({'params': net_params}, domain_points)\n",
    "        loss_dirichlet1 = dirichlet_residual1({'params': net_params}, boundary_points1)\n",
    "        loss_dirichlet2 = dirichlet_residual2({'params': net_params}, boundary_points2)\n",
    "        # loss_neumann = neumann_residual(neumann_derivatives, net_params, void_boundary_points)\n",
    "        return loss_pde1 + loss_pde2 + loss_dirichlet1 + loss_dirichlet2\n",
    "\n",
    "    # Evaluate the loss function and its gradient\n",
    "    loss_val, grad = jax.value_and_grad(lambda x: loss_total(x, boundary_samples, angle_samples1, angle_samples2, radius_samples))(params)\n",
    "\n",
    "    # Update model parameters\n",
    "    update, opt_state = opt.update(grad, opt_state, params) # update using \"grad\"\n",
    "    params = optax.apply_updates(params, update) # apply updates to \"params\"\n",
    "    return params, opt_state, key, loss_val\n",
    "\n",
    "# Training loop\n",
    "def train_loop(params, adam, opt_state, key, d_neumann: Callable = None):\n",
    "    losses = []\n",
    "    for _ in range(num_epochs): # \"_\" is used because the variable is not used in for loop\n",
    "        params, opt_state, key, loss_val = training_step(params, adam, opt_state, key)\n",
    "        losses.append(loss_val.item())\n",
    "    return losses, params, opt_state, key, loss_val # return final values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66337ad5",
   "metadata": {},
   "source": [
    "# Helper Functions for L-BFGS Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L-BFGS requires the parameters to be a single flattened array!\n",
    "def concat_params(params): # flatten the parameters\n",
    "    params, tree = jax.tree_util.tree_flatten(params) # \"params\" is flattened to a list of arrays\n",
    "    shapes = [param.shape for param in params] # shape of each array in the \"params\" list\n",
    "    return np.concatenate([param.reshape(-1) for param in params]), tree, shapes # concat to single 1D array\n",
    "\n",
    "def unconcat_params(params, tree, shapes): # unflatten the parameters\n",
    "    split_vec = np.split(params, onp.cumsum([onp.prod(shape, dtype=onp.int32) for shape in shapes])) # \"np.cumsum\" figures out the boundaries where to split the flattened \"params\"\n",
    "    split_vec = [vec.reshape(*shape) for vec, shape in zip(split_vec, shapes)] # reshape slices of vector (\"*\" unpack the tuple into individual arguments)\n",
    "    return jax.tree_util.tree_unflatten(tree, split_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a182b2",
   "metadata": {},
   "source": [
    "# Evaluation Points & Ground Truth Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ec65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation points\n",
    "x_points = np.linspace(0, 40, 200 + 1)\n",
    "y_points = np.linspace(0, 40, 200 + 1)\n",
    "X, Y = np.meshgrid(x_points, y_points, indexing='ij')\n",
    "X, Y = X.flatten(), Y.flatten()\n",
    "eval_points = np.array([X, Y]).T\n",
    "\n",
    "# Load evaluation solutions (by Ground Truth FEM)\n",
    "with open('data/eval_solutions.json', 'r') as f:\n",
    "    eval_sol = json.load(f)\n",
    "\n",
    "# Ground truth soution (200 x 200 cells)\n",
    "u_true = np.array(eval_sol) # shape: (n_points, 2)\n",
    "\n",
    "print(\"Evaluation points: \", np.array(eval_points).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c67af",
   "metadata": {},
   "source": [
    "# Train PINN & Approximate Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for the results\n",
    "y_results, domain_pts, times_adam, times_lbfgs, times_total, times_eval, l2_rel, var, arch\\\n",
    "    = dict({}), dict({}), dict({}), dict({}), dict({}), dict({}), dict({}), dict({}), dict({})\n",
    "\n",
    "count = 0 # architecture index\n",
    "for architecture in architecture_list :\n",
    "    print('Architecture : %s' %architecture)\n",
    "    times_adam_temp = [] # containers for 10 times training results\n",
    "    times_lbfgs_temp = []\n",
    "    times_total_temp = []\n",
    "    times_eval_temp = []\n",
    "    accuracy_temp = []\n",
    "    domain_pts_temp = []\n",
    "    for _ in range(10): # loop over 10 training runs\n",
    "        # Initialize Model\n",
    "        model = PDESolution(architecture)\n",
    "        key, key2 = jax.random.split(jax.random.PRNGKey(0)) # create two keys for independent use\n",
    "        batch_dim = 8 # dummy number(can be any value). Batch dimension will be reshaped after running \"model.init\".\n",
    "        feature_dim = 2 # dimension of input point (x, y coord)\n",
    "        # \"flax.linen.Module.init(key, dummy_input)\" triggers \"__call__\" (like \".apply\") and infers the shape of weights & biases\n",
    "        # where \"key\" is JAX-made PRNG key and \"dummy_input\" is the dummy input data.\n",
    "        net_params = model.init(key, np.ones((batch_dim, feature_dim)))['params'] # net_params: weights & biases initialized randomly\n",
    "        # geo_params = np.array([25., 30., 5.0, 2.0, np.pi/3]) # geo_params: x, y, a, b, gamma initialized by 1.0\n",
    "        geo_params = (25., 30., 5.0, 2.0, float(onp.pi/3)) # \"float(onp)\" for preventing the trouble when jax object is inside the tuple.\n",
    "        params: dict = {'network': net_params, 'geometry': geo_params}\n",
    "        masks: dict = {'network': True, 'geometry': (False, False, False, False, False)}\n",
    "        # False : freeze parameter (gradient will be zeroed out)\n",
    "        # True  : train parameter (gradient will be used)\n",
    "\n",
    "        # Initialize Adam Optimizer\n",
    "        adam = optax.adam(learning_rate = lr)\n",
    "        adam_masked = optax.masked(adam, masks)\n",
    "        opt_state = adam_masked.init(params) # opt_state : internal states of the Adam optimizer\n",
    "\n",
    "        # Start Training with Adam Optimizer\n",
    "        start_time = time.time()\n",
    "        losses, params, opt_state, key, loss_val = jax.block_until_ready(train_loop(params, adam_masked, opt_state, key))\n",
    "        adam_time = time.time() - start_time\n",
    "        times_adam_temp.append(adam_time)\n",
    "        print('Adam Training Time : %f secs' %adam_time)\n",
    "\n",
    "        # Generate random samples for L-BFGS optimization\n",
    "        lbfgs_boundary_samples = lhs(2, 250)\n",
    "        lbfgs_angle_samples1 = lhs(1, 150)\n",
    "        lbfgs_angle_samples2 = lhs(1, 2000)\n",
    "        lbfgs_radius_samples = lhs(1, 2000)\n",
    "\n",
    "        def ellipse(x_cen, y_cen, a, b, gamma, rotated_ang):\n",
    "            x = a * np.cos(rotated_ang) * np.cos(gamma) - b * np.sin(rotated_ang) * np.sin(gamma) + x_cen\n",
    "            y = a * np.cos(rotated_ang) * np.sin(gamma) + b * np.sin(rotated_ang) * np.cos(gamma) + y_cen\n",
    "            return np.array([x, y]).T\n",
    "\n",
    "        # Total loss functional\n",
    "        def loss_total(params, boundary_samples, angle_samples1, angle_samples2, radius_samples):\n",
    "            net_params = params['network']\n",
    "            geo_params = params['geometry']\n",
    "            x_cen, y_cen, a, b, gamma = geo_params # unpack geometric parameters\n",
    "\n",
    "            # Define the domain & external boundary points\n",
    "            lb = np.array([0., 0.]) # lower bound\n",
    "            ub = np.array([40., 40.]) # upper bound\n",
    "            boundary_points = lb + (ub - lb) * boundary_samples\n",
    "            boundary_points1 = np.column_stack((np.zeros_like(boundary_points[:, 0]), boundary_points[:, 1])) # latin hypercube sampling 150 points at x = 0\n",
    "            boundary_points2 = np.column_stack((boundary_points[:, 0], 40 * np.ones_like(boundary_points[:, 1])))\n",
    "\n",
    "            # Define the boundary points of the void\n",
    "            random_angle1 = 2 * np.pi * angle_samples1\n",
    "            void_boundary_points = ellipse(x_cen, y_cen, a, b, gamma, random_angle1)\n",
    "\n",
    "            # Define the domain points\n",
    "            random_angle2 = 2 * np.pi * angle_samples2\n",
    "            random_radius = np.sqrt(radius_samples)\n",
    "            domain_points = ellipse(x_cen, y_cen, a * random_radius, b * random_radius, gamma, random_angle2)\n",
    "            \n",
    "            # Define the loss function\n",
    "            loss_pde1 = pde_residual1({'params': net_params}, domain_points) # parameters to be used in \"model.apply\" should be in the dict with 'params' key.\n",
    "            loss_pde2 = pde_residual2({'params': net_params}, domain_points)\n",
    "            loss_dirichlet1 = dirichlet_residual1({'params': net_params}, boundary_points1)\n",
    "            loss_dirichlet2 = dirichlet_residual2({'params': net_params}, boundary_points2)\n",
    "            # loss_neumann = neumann_residual(neumann_derivatives, net_params, void_boundary_points)\n",
    "            return loss_pde1 + loss_pde2 + loss_dirichlet1 + loss_dirichlet2\n",
    "\n",
    "        # (Freeze geometric parameters)\n",
    "        def loss_total_frozen(params, boundary_samples, angle_samples1, angle_samples2, radius_samples):\n",
    "            loss_val, grad = jax.value_and_grad(lambda x: loss_total(x, boundary_samples, angle_samples1, \n",
    "                                                                     angle_samples2, radius_samples))(params)            \n",
    "            # Create a PyTree with the same structure as 'geometry', but filled with zeros\n",
    "            grad_frozen = jax.tree_util.tree_map(lambda g: np.zeros_like(g), grad['geometry'])\n",
    "            # Overwrite the geometry gradients with frozen gradients\n",
    "            grad['geometry'] = grad_frozen\n",
    "            # Flatten the gradients\n",
    "            flat_grad_frozen, _, _ = concat_params(grad)\n",
    "            return loss_val, flat_grad_frozen\n",
    "\n",
    "        init_point, tree, shapes = concat_params(params)\n",
    "\n",
    "        # L-BFGS Optimization\n",
    "        print('Starting L-BFGS Optimization')\n",
    "        start_time2 = time.time()\n",
    "        # results = tfp.optimizer.lbfgs_minimize(jax.value_and_grad(lambda x: loss_total_frozen(unconcat_params(x, tree, shapes), \n",
    "        #                                                                                lbfgs_boundary_samples, lbfgs_angle_samples1, \n",
    "        #                                                                                lbfgs_angle_samples2, lbfgs_radius_samples)),\n",
    "        #                                        init_point,\n",
    "        #                                        max_iterations = 50000,\n",
    "        #                                        num_correction_pairs = 50, # number of past updates to use for the approximation of the Hessian inverse.\n",
    "        #                                        f_relative_tolerance = 1.0*np.finfo(float).eps) # stopping criterion\n",
    "        results = tfp.optimizer.lbfgs_minimize(lambda x: loss_total_frozen(unconcat_params(x, tree, shapes), \n",
    "                                                                           lbfgs_boundary_samples, lbfgs_angle_samples1, \n",
    "                                                                           lbfgs_angle_samples2, lbfgs_radius_samples),\n",
    "                                        init_point,\n",
    "                                        max_iterations = 50000,\n",
    "                                        num_correction_pairs = 50, # number of past updates to use for the approximation of the Hessian inverse.\n",
    "                                        f_relative_tolerance = 1.0*np.finfo(float).eps) # stopping criterion\n",
    "        lbfgs_time = time.time() - start_time2\n",
    "        times_lbfgs_temp.append(lbfgs_time)\n",
    "        times_total_temp.append(adam_time + lbfgs_time)\n",
    "        print(\"L-BFGS training time : %.3f secs\" % lbfgs_time)\n",
    "\n",
    "        # Comparison to Ground Truth\n",
    "        tuned_params = unconcat_params(results.position, tree, shapes)\n",
    "\n",
    "        start_time3 = time.time()\n",
    "        # Pass the \"eval_points\" to the trained model\n",
    "        u_approx = jax.block_until_ready(model.apply({'params': tuned_params['network']}, np.stack((eval_points[:, 0], eval_points[:, 1]), axis=1)))\n",
    "        eval_time = time.time() - start_time3\n",
    "        times_eval_temp.append(eval_time)\n",
    "\n",
    "        # MSE\n",
    "        run_accuracy = (onp.linalg.norm(u_approx - u_true)) / onp.linalg.norm(u_true) # relative L2 error\n",
    "        accuracy_temp.append(run_accuracy)\n",
    "\n",
    "        # Save domain points (last generated domain points)\n",
    "        x_cen, y_cen, a, b, gamma = tuned_params['geometry']\n",
    "        random_angle2 = 2 * np.pi * lbfgs_angle_samples2\n",
    "        random_radius = np.sqrt(lbfgs_radius_samples)\n",
    "        final_domain_points = ellipse(x_cen, y_cen, a * random_radius, b * random_radius, gamma, random_angle2)\n",
    "\n",
    "    y_gt = u_true.tolist() # for storing into dict\n",
    "    y_results[count] = u_approx.tolist()\n",
    "    domain_pts[count] = final_domain_points.tolist()\n",
    "    times_adam[count] = onp.mean(times_adam_temp) # mean times across the 10 runs\n",
    "    times_lbfgs[count] = onp.mean(times_lbfgs_temp)\n",
    "    times_total[count] = onp.mean(times_total_temp)\n",
    "    times_eval[count] = onp.mean(times_eval_temp)\n",
    "    l2_rel[count] = onp.mean(accuracy_temp).tolist()\n",
    "    var[count] = onp.var(accuracy_temp).tolist() # variance of the error across the 10 runs\n",
    "    arch[count] = architecture_list[count]\n",
    "    count += 1\n",
    "\n",
    "    results = dict({'domain_pts': domain_pts,\n",
    "                    'y_results': y_results,\n",
    "                    'y_gt': y_gt})\n",
    "\n",
    "    evaluation = dict({'arch': arch,\n",
    "                       'times_adam': times_adam,\n",
    "                       'times_lbfgs': times_lbfgs,\n",
    "                       'times_total': times_total,\n",
    "                       'times_eval': times_eval,\n",
    "                       'l2_rel': l2_rel,\n",
    "                       'var': var})\n",
    "\n",
    "    sol_json = 'PINNs_results.json'\n",
    "    with open(sol_json, \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    eval_json = 'PINNs_evaluation.json'\n",
    "    with open(eval_json, \"w\") as f:\n",
    "        json.dump(evaluation, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf67ca",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df31838",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PINNs_results.json', 'r') as f:\n",
    "    data_results = json.load(f)\n",
    "\n",
    "with open('PINNs_evaluation.json', 'r') as f:\n",
    "    data_eval = json.load(f)\n",
    "\n",
    "# Slice results data\n",
    "domain_pts = data_results['domain_pts']\n",
    "y_results = data_results['y_results']\n",
    "y_gt = data_results['y_gt']\n",
    "\n",
    "arch = data_eval['arch']\n",
    "times_adam = data_eval['times_adam']\n",
    "times_lbfgs = data_eval['times_lbfgs']\n",
    "times_total = data_eval['times_total']\n",
    "times_eval = data_eval['times_eval']\n",
    "l2_rel = data_eval['l2_rel']\n",
    "var = data_eval['var']\n",
    "\n",
    "# Pick one architecture\n",
    "arch_idx = '8'\n",
    "arch_indices = sorted([int(k) for k in data_eval['arch'].keys()])\n",
    "arch_indices_str = [str(i) for i in arch_indices]\n",
    "# For instance, pick the first architecture index in data_results['y_results']\n",
    "# example_key = list(data_results['y_results'].keys())[0]  # first architecture\n",
    "domain_points = np.array(data_results['domain_pts'][arch_idx])  # shape (N, 2)\n",
    "u_approx   = np.array(data_results['y_results'][arch_idx])  # shape (N,)\n",
    "u_exact    = np.array(data_results['y_gt'])          # shape (N,)\n",
    "\n",
    "# Unpack X, Y\n",
    "X = domain_points[:, 0]\n",
    "Y = domain_points[:, 1]\n",
    "\n",
    "# Approximate solution (left)\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "sc1 = ax1.scatter(X, Y, u_approx, c=u_approx, cmap='viridis')\n",
    "sc1 = ax1.tricontourf(\n",
    "    X, Y, u_approx, \n",
    "    levels=50, \n",
    "    cmap='viridis'\n",
    ")\n",
    "ax1.set_title(f\"PINN Approx. Solution (Arch index={arch_idx})\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "fig.colorbar(sc1, ax=ax1, shrink=0.5)\n",
    "\n",
    "# Exact solution (right)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "sc2 = ax2.tricontourf(\n",
    "    X, Y, u_exact, \n",
    "    levels=50, \n",
    "    cmap='viridis'\n",
    ")\n",
    "ax2.set_title(\"Exact Solution\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "fig.colorbar(sc2, ax=ax2, shrink=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"2D_Poisson_PINNs_approx_vs_exact.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-fem-pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
